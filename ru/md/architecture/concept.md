sidebar_position: 1

# 4.1 Философия проектирования

- [4.1.1 Обзор](#411-обзор)
- [4.1.2 Архитектурная практика](#412-архитектурная-практика)

## 4.1.1 Обзор
Для ускорения вычислений ИИ производители чипов разработали различные специализированные архитектуры процессоров, такие как GPGPU, NPU, TPU и др. При выполнении кода планирования и прикладного кода эти специализированные процессоры требуют участия управляющего CPU, как показано ниже. Поэтому обычно приходится строить сложную гетерогенную систему планирования, которая координирует передачу данных и синхронизацию между CPU и XPU.
![architect](./images/architect.webp)

Чтобы обеспечить универсальность и удобство ИИ-вычислений, SpacemiT, опираясь на собственные разработки CPU-ядер, на базе стандартных ядер RISC-V интегрировал Tensor Core прямо в CPU. Набор инструкций RISC-V используется как единый аппаратно-программный интерфейс для скалярных, векторных и матричных ИИ-вычислений. Это позволяет обычному ПО и моделям ИИ работать на одном ядре ИИ RISC-V и через стандартный поток выполнения программы обеспечивать обмен данными и событиями между ПО и ИИ-вычислениями, тем самым выполняя приложение целиком. Мы называем этот подход — использование инструкций RISC-V как единого интерфейса для скалярных, векторных и матричных вычислений ИИ — **технологией однородной интеграции**. CPU с такими возможностями называют **AI CPU** или **ядром интеллектуальных вычислений**.

**AI CPU** сохраняет привычную модель программирования CPU. Разработчики могут использовать потоки Linux для управления вычислениями ИИ, не прибегая к гетерогенному планировщику и сложному управлению драйверами. Поскольку архитектура основана на ***RISC-V***, она легко интегрируется в экосистему открытого ПО и существующие рабочие процессы. Кроме того, **AI CPU** сочетает параллельные вычисления и управляющую логику, что хорошо подходит для инференса моделей MoE.

В вычислениях ИИ используются три типа вычислений:
- Скалярные вычисления обеспечиваются стандартным набором инструкций ***RISC-V***;
- Векторные вычисления обеспечиваются набором инструкций ***RISC-V*** Vector 1.0;
- Матричные вычисления ИИ обеспечиваются набором инструкций ***RISC-V*** [matrix-расширения](./instruction.md).

## 4.1.2 Архитектурная практика
Мы уже выпустили первое поколение чипов с **AI CPU** — **K1**. В нем четыре универсальных CPU-ядра **X60** и четыре ядра интеллектуальных вычислений **A60**. В ядре **A60** ширина RISC-V Vector составляет 256 бит. Теоретическая производительность матричных и векторных вычислений приведена ниже; методику расчета можно посмотреть в [описании набора инструкций](./instruction.md).
Матрическая производительность: 0.5 TOPS/Core (Int8), 2 TOPS/Cluster (Int8)
Векторная производительность:
- 0.128 TOPS/Core (Int8), 0.5 TOPS/Cluster (Int8)
- 0.064 TOPS/Core (FP16), 0.25 TOPS/Cluster (FP16)
- 0.032 TOPS/Core (FP32)

На основе open-source проекта [cpfp](https://github.com/pigirons/cpufp) мы протестировали ядро **A60** в **AI CPU** K1. Результаты измерений ниже:
~~~
$ ./cpufp --thread_pool=[0]
Number Threads: 1
Thread Pool Binding: 0
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| ime             | vmadot(s32,s8,s8)      | 511.53 GOPS      |
| ime             | vmadotu(u32,u8,u8)     | 511.5 GOPS       |
| ime             | vmadotus(s32,u8,s8)    | 511.53 GOPS      |
| ime             | vmadotsu(s32,s8,u8)    | 511.51 GOPS      |
| ime             | vmadotslide(s32,s8,s8) | 511.51 GOPS      |
| vector          | vfmacc.vf(f16,f16,f16) | 66.722 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 63.936 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 33.36 GFLOPS     |
| vector          | vfmacc.vv(f32,f32,f32) | 31.968 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 16.679 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 15.985 GFLOPS    |
---------------------------------------------------------------
For cluster 0(with ime extension), 4 cores:
$ ./cpufp --thread_pool=[0-3]
Number Threads: 4
Thread Pool Binding: 0 1 2 3
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| ime             | vmadot(s32,s8,s8)      | 2.046 TOPS       |
| ime             | vmadotu(u32,u8,u8)     | 2.0462 TOPS      |
| ime             | vmadotus(s32,u8,s8)    | 2.0461 TOPS      |
| ime             | vmadotsu(s32,s8,u8)    | 2.0462 TOPS      |
| ime             | vmadotslide(s32,s8,s8) | 2.0461 TOPS      |
| vector          | vfmacc.vf(f16,f16,f16) | 266.88 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 255.75 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 133.43 GFLOPS    |
| vector          | vfmacc.vv(f32,f32,f32) | 127.85 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 66.709 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 63.935 GFLOPS    |
---------------------------------------------------------------
For 2 clusters, 8 cores:
$ ./cpufp --thread_pool=[0-7]
Number Threads: 8
Thread Pool Binding: 0 1 2 3 4 5 6 7
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| vector          | vfmacc.vf(f16,f16,f16) | 533.65 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 511.45 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 266.89 GFLOPS    |
| vector          | vfmacc.vv(f32,f32,f32) | 255.75 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 133.42 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 127.86 GFLOPS    |
---------------------------------------------------------------
~~~
