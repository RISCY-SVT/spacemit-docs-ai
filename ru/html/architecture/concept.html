<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>4.1 Философия проектирования</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a class="home-link" href="../index.html">Документация ИИ SpacemiT</a>
    </div>
  </header>
  <main class="container content">
<h1 id="41-философия-проектирования">4.1 Философия проектирования</h1>
<ul>
<li><a href="#411-обзор">4.1.1 Обзор</a></li>
<li><a href="#412-архитектурная-практика">4.1.2 Архитектурная практика</a></li>
</ul>
<h2 id="411-обзор">4.1.1 Обзор</h2>
<p>Для ускорения вычислений ИИ производители чипов разработали различные специализированные архитектуры процессоров, такие как GPGPU, NPU, TPU и др. При выполнении кода планирования и прикладного кода эти специализированные процессоры требуют участия управляющего CPU, как показано ниже. Поэтому обычно приходится строить сложную гетерогенную систему планирования, которая координирует передачу данных и синхронизацию между CPU и XPU.
<img alt="architect" src="./images/architect.webp" /></p>
<p>Чтобы обеспечить универсальность и удобство ИИ-вычислений, SpacemiT, опираясь на собственные разработки CPU-ядер, на базе стандартных ядер RISC-V интегрировал Tensor Core прямо в CPU. Набор инструкций RISC-V используется как единый аппаратно-программный интерфейс для скалярных, векторных и матричных ИИ-вычислений. Это позволяет обычному ПО и моделям ИИ работать на одном ядре ИИ RISC-V и через стандартный поток выполнения программы обеспечивать обмен данными и событиями между ПО и ИИ-вычислениями, тем самым выполняя приложение целиком. Мы называем этот подход — использование инструкций RISC-V как единого интерфейса для скалярных, векторных и матричных вычислений ИИ — <strong>технологией однородной интеграции</strong>. CPU с такими возможностями называют <strong>AI CPU</strong> или <strong>ядром интеллектуальных вычислений</strong>.</p>
<p><strong>AI CPU</strong> сохраняет привычную модель программирования CPU. Разработчики могут использовать потоки Linux для управления вычислениями ИИ, не прибегая к гетерогенному планировщику и сложному управлению драйверами. Поскольку архитектура основана на <strong><em>RISC-V</em></strong>, она легко интегрируется в экосистему открытого ПО и существующие рабочие процессы. Кроме того, <strong>AI CPU</strong> сочетает параллельные вычисления и управляющую логику, что хорошо подходит для инференса моделей MoE.</p>
<p>В вычислениях ИИ используются три типа вычислений:
- Скалярные вычисления обеспечиваются стандартным набором инструкций <strong><em>RISC-V</em></strong>;
- Векторные вычисления обеспечиваются набором инструкций <strong><em>RISC-V</em></strong> Vector 1.0;
- Матричные вычисления ИИ обеспечиваются набором инструкций <strong><em>RISC-V</em></strong> <a href="./instruction.html">matrix-расширения</a>.</p>
<h2 id="412-архитектурная-практика">4.1.2 Архитектурная практика</h2>
<p>Мы уже выпустили первое поколение чипов с <strong>AI CPU</strong> — <strong>K1</strong>. В нем четыре универсальных CPU-ядра <strong>X60</strong> и четыре ядра интеллектуальных вычислений <strong>A60</strong>. В ядре <strong>A60</strong> ширина RISC-V Vector составляет 256 бит. Теоретическая производительность матричных и векторных вычислений приведена ниже; методику расчета можно посмотреть в <a href="./instruction.html">описании набора инструкций</a>.
Матрическая производительность: 0.5 TOPS/Core (Int8), 2 TOPS/Cluster (Int8)
Векторная производительность:
- 0.128 TOPS/Core (Int8), 0.5 TOPS/Cluster (Int8)
- 0.064 TOPS/Core (FP16), 0.25 TOPS/Cluster (FP16)
- 0.032 TOPS/Core (FP32)</p>
<p>На основе open-source проекта <a href="https://github.com/pigirons/cpufp">cpfp</a> мы протестировали ядро <strong>A60</strong> в <strong>AI CPU</strong> K1. Результаты измерений ниже:</p>
<pre><code>$ ./cpufp --thread_pool=[0]
Number Threads: 1
Thread Pool Binding: 0
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| ime             | vmadot(s32,s8,s8)      | 511.53 GOPS      |
| ime             | vmadotu(u32,u8,u8)     | 511.5 GOPS       |
| ime             | vmadotus(s32,u8,s8)    | 511.53 GOPS      |
| ime             | vmadotsu(s32,s8,u8)    | 511.51 GOPS      |
| ime             | vmadotslide(s32,s8,s8) | 511.51 GOPS      |
| vector          | vfmacc.vf(f16,f16,f16) | 66.722 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 63.936 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 33.36 GFLOPS     |
| vector          | vfmacc.vv(f32,f32,f32) | 31.968 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 16.679 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 15.985 GFLOPS    |
---------------------------------------------------------------
For cluster 0(with ime extension), 4 cores:
$ ./cpufp --thread_pool=[0-3]
Number Threads: 4
Thread Pool Binding: 0 1 2 3
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| ime             | vmadot(s32,s8,s8)      | 2.046 TOPS       |
| ime             | vmadotu(u32,u8,u8)     | 2.0462 TOPS      |
| ime             | vmadotus(s32,u8,s8)    | 2.0461 TOPS      |
| ime             | vmadotsu(s32,s8,u8)    | 2.0462 TOPS      |
| ime             | vmadotslide(s32,s8,s8) | 2.0461 TOPS      |
| vector          | vfmacc.vf(f16,f16,f16) | 266.88 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 255.75 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 133.43 GFLOPS    |
| vector          | vfmacc.vv(f32,f32,f32) | 127.85 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 66.709 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 63.935 GFLOPS    |
---------------------------------------------------------------
For 2 clusters, 8 cores:
$ ./cpufp --thread_pool=[0-7]
Number Threads: 8
Thread Pool Binding: 0 1 2 3 4 5 6 7
---------------------------------------------------------------
| Instruction Set | Core Computation       | Peak Performance |
| vector          | vfmacc.vf(f16,f16,f16) | 533.65 GFLOPS    |
| vector          | vfmacc.vv(f16,f16,f16) | 511.45 GFLOPS    |
| vector          | vfmacc.vf(f32,f32,f32) | 266.89 GFLOPS    |
| vector          | vfmacc.vv(f32,f32,f32) | 255.75 GFLOPS    |
| vector          | vfmacc.vf(f64,f64,f64) | 133.42 GFLOPS    |
| vector          | vfmacc.vv(f64,f64,f64) | 127.86 GFLOPS    |
---------------------------------------------------------------
</code></pre>
  </main>
</body>
</html>
